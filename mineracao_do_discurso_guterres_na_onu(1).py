# -*- coding: utf-8 -*-
"""Mineracao do Discurso Guterres na ONU

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rZNlD-B7Sac3_1XZ9Hfk01zdMY1a_sfN
"""

pip install nltk #instalando o nltk

import nltk 
import re 
import string
import pandas as pd
import numpy as np  
#importa

nltk.download ('all') #baixa tudo no nltk

from nltk.tokenize import sent_tokenize
nltk.download('punkt')
from nltk.tokenize import word_tokenize

#subindo no google colab
from google.colab import files
uploaded = files.upload()

#fazendo a leitura do arquivo
f = open('DiscursoGuterres.txt', 'r')
texto = ''
while 1:
    line = f.readline()
    if not line: break
    texto += line
f.close()

print(texto)
print(type(texto))

f #meu arquivo

texto #meu texto

"""#Limpeza

remoção das pontuações tirando maiusculas e minusculas
"""

def processamento (texto): 
 texto_formatado=texto.lower() 
 return texto_formatado

texto_formatado=processamento(texto)
texto_formatado

"""# Tokenization 

Transforma elementos do seu texto em tokens, ou seja, strings dentro de uma lista

É o nome dado para o processo de dividir uma grande quantidade de texto em pequenas quantidades - essas pequenas quantidades são chamadas de tokens. Essa é uma divisão importante para fazer análises textuais.

O nltk possui um módulo chamado tokenize que facilita o processo de divisão de um texto. A função word_tokenize() divide um texto por palavras e pontuações:
"""

# Quebra em palavras
tokenized_word = word_tokenize(texto_formatado)
print(tokenized_word)

# Aqui também deixamos as palavras em letras minúsculas
tokenized_word2 = [w.lower() for w in tokenized_word]
print(tokenized_word2)

"""#Remover Stopwords
Existem palavras na construção textual chamadas de stopwords, tais palavras, dentro de uma abordagem de NLP, são irrelevantes e sua remoção colaboram com a analise textual. Alguns exemplos de stopwords comuns no português são preposições (em, na, no, etc), artigos (a, o,os, etc),conjunções (e, mas, etc), entre outras.
"""

#1)importar analise de stopwords e também visualizar as existentes
from nltk.corpus import stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words('portuguese'))
print(stop_words)

#2) aqui eu tiro o que nao quero
stop_words.update(('uso', '/','i',',',';','l','.',':', '***','-','–','|', '!', '?'))
print(stop_words)

#3) Remover essas stopwords
tokenized_word_3 = []
for w in tokenized_word2:
    if w not in stop_words:
        tokenized_word_3.append(w)

tokenized_word_3

# Analisa a distribuição das palavras
from nltk.probability import FreqDist
fdist = FreqDist(tokenized_word_3)
fdist.most_common(13)

# Gráfico de distribuiçao de palavras
import matplotlib.pyplot as plt
plt.figure()
fdist.plot(20,cumulative=False)

#Outra forma de ver duas palavras mais comuns
Comum=fdist.most_common(2)
Comum

"""
#Outras analises"""

#Quantas vezes a palavra repete
texto.count('pessoas')

tokenized_word_3.count('pessoas')

tokenized_word_3.count('mulheres')

personagens = ['terra', 'pessoas', 'mulheres', 'climática']
for p in personagens:
 print('{}: {}'.format(p, tokenized_word_3.count(p)))

"""#Possibilidade de gráficos"""

#Grafico de linha
import matplotlib.pyplot
personagens = ['terra', 'pessoas', 'mulheres', 'pobres']
valores = [7, 3, 2, 1]
matplotlib.pyplot.ylim(0, 10)
matplotlib.pyplot.plot(personagens,valores)
matplotlib.pyplot.show()

#grafico barras horizontais 
plt.barh(personagens,valores, color='black') 
plt.ylabel('Palavras citadas',fontsize=12) 
plt.xlabel('Valores',fontsize=12)
plt.title('Citações mais frequentes no discuso',fontsize=12)
plt.show()

#grafico barras horizontais com definições de espaço e titulo 
figura = plt.figure()
ax = figura.add_axes([0,0,0.9,1])
personagens = ['Terra', 'Pessoas', 'Mulheres', 'Pobres']
valores = [7, 3, 2, 1]
ax.barh(personagens, valores, color = "black")
ax.set_title("Citações mais frequentes no discurso", fontsize=14)
ax.set_xlabel("Valores", fontsize=14)
ax.set_ylabel("Palavras citadas", fontsize=14)
plt.show()

#grafico de barras com definições de espaço e titulo
figura = plt.figure()
ax = figura.add_axes([0,0,1.0,1])
personagens = ['terra', 'pessoas', 'mulheres', 'pobres']
valores = [7, 3, 2, 1]
ax.bar(personagens, valores, color = "black")
ax.set_title("Citações mais frequentes no discuso", fontsize=14)
ax.set_xlabel("Palavras citadas", fontsize=13)
ax.set_ylabel("Valores", fontsize=13)
plt.show()

"""#Possibilidade de tabelas"""

#Acriando uma tabela comum
citou_1 = pd.Series({'Palavra citada': 'terra', 'Repetições': 7})
citou_2 = pd.Series({'Palavra citada': 'pessoas', 'Repetições': 3})
citou_3 = pd.Series({'Palavra citada': 'bem-estar', 'Repetições': 2})
citou_4 = pd.Series({'Palavra citada': 'milhões', 'Repetições': 2})
citou_5 = pd.Series({'Palavra citada': 'seca', 'Repetições': 2})
citou_6 = pd.Series({'Palavra citada': 'mudanças', 'Repetições': 2})
citou_7 = pd.Series({'Palavra citada': 'climáticas', 'Repetições': 2})
citou_8 = pd.Series({'Palavra citada': 'restauração', 'Repetições': 2})
df = pd.DataFrame([citou_1, citou_2, citou_3, citou_4, citou_5, citou_6, citou_7, citou_8])
df


#Tabela mais agradável 
import plotly.graph_objects as go 
  
fig = go.Figure(data=[go.Table( 
    header=dict(values=['Citações no discurso', 'Repetições']), 
    cells=dict(values=[['Terra', 'Pessoas', 'Bem-estar', 'Milhões','Seca','Mudanças climáticas', 'Restauração'], 
                       [7, 3, 2, 2, 2, 2, 2]])) 
]) 
fig.update_layout(width=500, height=900)
fig.show()
